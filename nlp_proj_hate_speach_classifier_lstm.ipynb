{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "nlp_proj_hate_speach_classifier_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/walt-r/hate_speech_nlp/blob/main/nlp_proj_hate_speach_classifier_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFQT1CZGkMVJ"
      },
      "source": [
        "# Hate Speech Classification\n",
        "## Detect toxic content to improve online conversations\n",
        "Inspired by quora_classifier_lstm_new\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ2jw6OlkMVK",
        "outputId": "ead990fa-f18a-4309-b236-e1db73773bd1"
      },
      "source": [
        "!wget https://github.com/t-davidson/hate-speech-and-offensive-language/blob/master/data/labeled_data.csv -O hate_speech_data.csv\n",
        "# !wget https://github.com/t-davidson/hate-speech-and-offensive-language/blob/master/data/labeled_data.p -O hate_speech_data.p"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-24 23:58:40--  https://github.com/t-davidson/hate-speech-and-offensive-language/blob/master/data/labeled_data.csv\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘hate_speech_data.csv’\n",
            "\n",
            "hate_speech_data.cs     [ <=>                ] 104.48K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2021-03-24 23:58:40 (11.0 MB/s) - ‘hate_speech_data.csv’ saved [106991]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnrBk_DwkMVL"
      },
      "source": [
        "import random\n",
        "import os\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "import torch   \n",
        "from torchtext import data \n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywRd3TxnkMVL"
      },
      "source": [
        "#Reproducing same results\n",
        "SEED = 2315\n",
        "\n",
        "#Torch\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "#Cuda algorithms\n",
        "torch.backends.cudnn.deterministic = True "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDwJRbGTkMVM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-2121-jkMVM"
      },
      "source": [
        "### Load custom dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHnR47R2VUWj"
      },
      "source": [
        "# Missing 30% of data from error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0Yyh584W-SM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "LiEahtGikMVM",
        "outputId": "eea5e1f4-709d-40af-a8c3-81ce82af479f"
      },
      "source": [
        "df = pd.read_csv('labeled_data_index.csv') #, error_bad_lines=False) \n",
        "# df = pd.read_csv('hate_speech_data.csv') #, error_bad_lines=False) \n",
        "\n",
        "# df = pd.read_pickle('hate_speech_data.p')\n",
        "\n",
        "print (f\"Number of records: {len(df)}\")\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of records: 24783\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  count  ...  class                                              tweet\n",
              "0      0      3  ...      2  !!! RT @mayasolovely: As a woman you shouldn't...\n",
              "1      1      3  ...      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
              "2      2      3  ...      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
              "3      3      3  ...      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
              "4      4      6  ...      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeWgkgM_sBik",
        "outputId": "8f5c099a-ecf7-428b-a5d8-87188d11cf04"
      },
      "source": [
        "df['class'].unique()\n",
        "df['count'].unique()\n",
        "df['class'].value_counts()\n",
        "# class 0 is hate_speach; 1 is offensive language; 2 is neither\n",
        "# df[df['class'] == 0]['tweet'].to_list()[-10:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    19190\n",
              "2     4163\n",
              "0     1430\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWpylsiIDYmC"
      },
      "source": [
        "# df[df['class'] < 2]['class'].value_counts()\n",
        "df['target'] = df['class'].apply(lambda x: 1 if x == 2 else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpdum3DaNYB3",
        "outputId": "93dc6c44-d6a6-4a36-87f7-d42416bab4dd"
      },
      "source": [
        "df['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    20620\n",
              "1     4163\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnIQ3xaVNtLq",
        "outputId": "6af01134-e76a-4304-e408-598e408c64b3"
      },
      "source": [
        "# find and drop percent of target == 0 rows\n",
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "print(df.shape)\n",
        "# df[df['target']==0].index.to_list()\n",
        "drop_offensive = random.sample(df[df['target']==0].index.to_list(), 15000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24783, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYoipTPVUbLF",
        "outputId": "78cba899-3089-46d2-ba1a-8a30f30b99d7"
      },
      "source": [
        "df = df.drop(index = drop_offensive)\n",
        "df['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5620\n",
              "1    4163\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYx-kshlkMVN"
      },
      "source": [
        "df['length'] = df['tweet'].apply(lambda s: len(s.split()))\n",
        "df.sort_values(by=['length'], ascending=False, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "0SVN8_rakMVN",
        "outputId": "593a3b48-1dfc-4b57-c92b-b30ade592d23"
      },
      "source": [
        "df['length'].hist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa3683d9a50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvNC126dkMVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f341fa5-e881-4d2a-8c69-8d72a4802caf"
      },
      "source": [
        "print(df[(df['length'] >= 5) & (df['length'] <= 28)].shape)\n",
        "df = df[(df['length'] >= 5) & (df['length'] <= 30)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9125, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "uAF_cmBgkMVO",
        "outputId": "60b3078e-2d95-466d-bc4e-f94ba22522d7"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "      <th>target</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10429</th>\n",
              "      <td>10707</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>I hate a bitch that love a bitch that say she ...</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7441</th>\n",
              "      <td>7652</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>A lady approached me asking me if I was religi...</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11510</th>\n",
              "      <td>11803</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>If I were born black; \\nI would have tons of k...</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24266</th>\n",
              "      <td>24770</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>niggas are jus like btchs talking bout a hoe t...</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8186</th>\n",
              "      <td>8413</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Bro everybody is a ho then, fuck it, your favo...</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       index  count  ...  target  length\n",
              "10429  10707      3  ...       0      30\n",
              "7441    7652      3  ...       0      30\n",
              "11510  11803      3  ...       0      30\n",
              "24266  24770      3  ...       0      30\n",
              "8186    8413      3  ...       0      30\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHgV_WhskMVO"
      },
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import Vocab\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo4_AwDykMVP"
      },
      "source": [
        "# This step takes few minutes\n",
        "\n",
        "counter = Counter()\n",
        "for _, row in df.iterrows():\n",
        "    counter.update(tokenizer(row['tweet']))\n",
        "\n",
        "vocab = Vocab(counter, min_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THozdaIrkMVP",
        "outputId": "d53817d6-1422-4e32-e80f-8bfc15bf6476"
      },
      "source": [
        "print(f\"Size of TEXT vocabulary: {len(vocab)}\\n\")\n",
        "\n",
        "print(f\"Commonly used words: {vocab.freqs.most_common(10)}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of TEXT vocabulary: 22678\n",
            "\n",
            "Commonly used words: [('.', 9742), (\"'\", 3860), ('i', 3637), ('a', 3520), ('the', 3277), ('rt', 3021), (',', 2669), ('you', 2271), ('to', 2162), ('bitch', 2070)]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdBnFHe9kMVP"
      },
      "source": [
        "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
        "\n",
        "label_pipeline = lambda x: int(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J2N6JhQkMVQ"
      },
      "source": [
        "### Custom DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fyXLGR0kMVQ",
        "outputId": "17ee3e74-0f45-4266-9dc1-64b0b9e524db"
      },
      "source": [
        "#Split into training and validation datasets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(df, test_size=0.5)\n",
        "train, valid = train_test_split(train, test_size=0.4)\n",
        "\n",
        "train.sort_values(by=['length'], ascending=False, inplace=True)\n",
        "test.sort_values(by=['length'], ascending=False, inplace=True)\n",
        "valid.sort_values(by=['length'], ascending=False, inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "7dJfn_ygkMVR",
        "outputId": "5d02a8b6-6314-4317-c856-349f4b33ebfc"
      },
      "source": [
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "      <th>target</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23694</th>\n",
              "      <td>24188</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>but I'd rather be a free man in my grave\\nthan...</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17495</th>\n",
              "      <td>17893</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>RT @SweetiePaii: RT if you listen to these ban...</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10856</th>\n",
              "      <td>11138</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>I remember when this lil bitch caught me slipp...</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8186</th>\n",
              "      <td>8413</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Bro everybody is a ho then, fuck it, your favo...</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10099</th>\n",
              "      <td>10372</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>I can jig, but I can't jig jig. &amp;#128514; like...</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24414</th>\n",
              "      <td>24920</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sheryl crow being the bae</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21182</th>\n",
              "      <td>21640</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Stop using the word \"redskin(s)\".</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>800</th>\n",
              "      <td>816</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>#WhatImCraving Peanut Butter Oreos &amp;lt;3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9477</th>\n",
              "      <td>9737</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Gold diggin ass bitch lol</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8656</th>\n",
              "      <td>8895</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Dat nicca had Jordan cleats!</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4613 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index  count  ...  target  length\n",
              "23694  24188      3  ...       0      30\n",
              "17495  17893      3  ...       1      30\n",
              "10856  11138      3  ...       0      30\n",
              "8186    8413      3  ...       0      30\n",
              "10099  10372      3  ...       1      30\n",
              "...      ...    ...  ...     ...     ...\n",
              "24414  24920      3  ...       1       5\n",
              "21182  21640      3  ...       0       5\n",
              "800      816      3  ...       1       5\n",
              "9477    9737      3  ...       0       5\n",
              "8656    8895      3  ...       0       5\n",
              "\n",
              "[4613 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwXiJjMNkMVR"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class PandasDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.dataframe = dataframe\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.dataframe.iloc[index]\n",
        "\n",
        "def generate_batch(batch):\n",
        "    label_list, text_list, text_length_list = [], [], []\n",
        "    SEQSIZE = len(batch[0]['tweet'].split())\n",
        "    for row in batch:\n",
        "        _text = row['tweet']\n",
        "        _label = row['target'] \n",
        "        label_list.append(label_pipeline(_label))\n",
        "        processed_text = text_pipeline(_text)[:SEQSIZE]\n",
        "        text_length_list.append(len(processed_text))\n",
        "        processed_text += [1]*(SEQSIZE-len(processed_text))\n",
        "        text_list.append(processed_text)\n",
        "    label_list = torch.tensor(label_list, dtype=torch.float32)\n",
        "    text_list = torch.tensor(text_list, dtype=torch.int64)\n",
        "    text_length_list = torch.tensor(text_length_list, dtype=torch.int64)\n",
        "    return label_list.to(device), text_list.to(device), text_length_list\n",
        "    \n",
        "batch_size = 64\n",
        "\n",
        "dataloader_train = DataLoader(PandasDataset(train), batch_size=batch_size, shuffle=False, collate_fn=generate_batch)\n",
        "\n",
        "dataloader_test = DataLoader(PandasDataset(test), batch_size=batch_size, shuffle=False, collate_fn=generate_batch)\n",
        "\n",
        "dataloader_valid = DataLoader(PandasDataset(valid), batch_size=batch_size, shuffle=False, collate_fn=generate_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTa65N3bkMVR",
        "outputId": "0acd340a-59dd-4010-b1b3-144f5f34e318"
      },
      "source": [
        "len(dataloader_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oYMiDwgkMVS"
      },
      "source": [
        "### LSTM Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Zfuj0OYkMVS"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    #define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers, \n",
        "                 bidirectional, dropout):\n",
        "        \n",
        "        #Constructor\n",
        "        super().__init__()          \n",
        "        \n",
        "        #embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        #lstm layer\n",
        "        self.lstm = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=num_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        \n",
        "        #dense layer\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        \n",
        "        #activation function\n",
        "        self.act = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        #text = [batch size,sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        #embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "        #packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, \n",
        "                                                            text_lengths,\n",
        "                                                            batch_first=True,\n",
        "                                                            enforce_sorted=False)\n",
        "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "\n",
        "        #concat the final forward and backward hidden state\n",
        "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs=self.fc(hidden)\n",
        "\n",
        "        #Final activation function\n",
        "        outputs=self.act(dense_outputs)\n",
        "        \n",
        "        return outputs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKQhp9LfkMVT"
      },
      "source": [
        "#### Instantiate a LSTM Classifier model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8ted3ThkMVT"
      },
      "source": [
        "#define hyperparameters\n",
        "size_of_vocab = len(vocab)\n",
        "embedding_dim = 100\n",
        "hidden_dim = 32\n",
        "output_dim = 1\n",
        "num_layers = 2\n",
        "bidirection = True\n",
        "dropout = 0.2\n",
        "\n",
        "#instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, hidden_dim, output_dim, num_layers, \n",
        "                   bidirectional = True, dropout = dropout)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfKDgJ6hkMVT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFvKfHC7kMVU",
        "outputId": "96378d69-f1cf-47c9-c642-1dcfbfd14e6d"
      },
      "source": [
        "#architecture\n",
        "print(model)\n",
        "\n",
        "#No. of trainable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "# #Initialize the pretrained embedding  ()\n",
        "# pretrained_embeddings = TEXT.vocab.vectors\n",
        "# # model.embedding.weight.data.copy_(pretrained_embeddings) # TODO PLEASE USE THIS FOR LSTM\n",
        "\n",
        "# print(pretrained_embeddings.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(22678, 100)\n",
            "  (lstm): LSTM(100, 32, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (act): Sigmoid()\n",
            ")\n",
            "The model has 2,327,257 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNzl2EWAkMVU"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "#define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "#define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(preds)\n",
        "    \n",
        "    correct = (rounded_preds == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "#push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-SxQoyUkMVV",
        "outputId": "f0ca1615-a9de-41ad-c667-cf26bb221158"
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfrlcm5pkMVV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZVi1ul7kMVV"
      },
      "source": [
        "### Model Train function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMQzp_QKkMVV"
      },
      "source": [
        "def train(model, dataloader, optimizer, criterion):\n",
        "    \n",
        "    #initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    #set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for idx, (label, text, text_lengths) in enumerate(dataloader):\n",
        "        \n",
        "        #resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "\n",
        "        #convert to 1D tensor\n",
        "        predictions = model(text, text_lengths).squeeze()\n",
        "    \n",
        "        #compute the loss\n",
        "        loss = criterion(predictions, label)\n",
        "        \n",
        "        #compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, label)   \n",
        "        \n",
        "        #backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        #update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        #loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "        if idx % 1000 == 0:\n",
        "            print (f\"Completed {idx}/{len(dataloader)}\")\n",
        "    return epoch_loss / len(dataloader), epoch_acc / len(dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQER4oiokMVW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZspAKIySkMVW"
      },
      "source": [
        "### Model Evaluate function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su2gNTpykMVW"
      },
      "source": [
        "def evaluate(model, dataloader, criterion):\n",
        "    \n",
        "    #initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    #deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for _, (label, text, text_lengths) in enumerate(dataloader):\n",
        "        \n",
        "            #predict\n",
        "            predictions = model(text, text_lengths).squeeze()\n",
        "            \n",
        "            #compute loss and accuracy\n",
        "            loss = criterion(predictions, label)\n",
        "            acc = binary_accuracy(predictions, label)\n",
        "            \n",
        "            #keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(dataloader), epoch_acc / len(dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhw5MbnrkMVX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ijbht-dkMVX"
      },
      "source": [
        "### Check model's forward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynGlTHRVkMVX",
        "outputId": "bf93d036-22ac-44ed-d808-3d00045156bd"
      },
      "source": [
        "#Check model device type\n",
        "next(model.parameters()).is_cuda, device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, device(type='cuda'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExL7If9lkMVY",
        "outputId": "1b93cf3c-072c-4458-8e92-4ce200c4dbee"
      },
      "source": [
        "len(dataloader_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y6LqX5rkMVY",
        "outputId": "6388408b-94f3-45a1-dd97-1c0964c2291c"
      },
      "source": [
        "for idx, (label, text, text_lengths) in enumerate(dataloader_train):\n",
        "    print (\"text.shape: \", text.shape)\n",
        "    predictions = model(text, text_lengths)\n",
        "    print (\"predictions.shape: \", predictions.shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text.shape:  torch.Size([64, 30])\n",
            "predictions.shape:  torch.Size([64, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLJRvF8zkMVY",
        "outputId": "225c5998-4d12-41c2-d925-09abe2283d04"
      },
      "source": [
        "text[0], predictions[0][:10], label[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([  67,   32, 1479,  150,   99,  663,   48,   77,    5,  282,   16,    3,\n",
              "           22,   47,  241,    8,    4,  150,  217,    4,  295,   60,  432,   28,\n",
              "            5,  282,   47,  322,   77,  217], device='cuda:0'),\n",
              " tensor([0.5365], device='cuda:0', grad_fn=<SliceBackward>),\n",
              " tensor([0., 0., 1., 1., 0., 1., 0., 0., 0., 1.], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvXFRX9JkMVZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rogF2xW_kMVZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owlI1k00kMVZ"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "This step takes around ~4 min"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5SRouBikMVZ",
        "outputId": "9abe90d9-5060-4838-e86d-0e0c58afbcb2"
      },
      "source": [
        "model_path = 'saved_weights.pt'\n",
        "\n",
        "N_EPOCHS = 5\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    ts_string = datetime.now().strftime(\"%m/%d/%Y %H:%M:%S\")\n",
        "    print(f'\\n {ts_string} Epoch: {epoch}')\n",
        "    #train the model\n",
        "    train_loss, train_acc = train(model, dataloader_train, optimizer, criterion)\n",
        "    \n",
        "    #evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, dataloader_valid, criterion)\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 03/25/2021 03:50:21 Epoch: 0\n",
            "Completed 0/44\n",
            "\t Train Loss: 0.232 | Train Acc: 91.05%\n",
            "\t Val. Loss: 0.447 |  Val. Acc: 81.64%\n",
            "\n",
            " 03/25/2021 03:50:22 Epoch: 1\n",
            "Completed 0/44\n",
            "\t Train Loss: 0.141 | Train Acc: 95.49%\n",
            "\t Val. Loss: 0.526 |  Val. Acc: 81.27%\n",
            "\n",
            " 03/25/2021 03:50:23 Epoch: 2\n",
            "Completed 0/44\n",
            "\t Train Loss: 0.096 | Train Acc: 96.98%\n",
            "\t Val. Loss: 0.530 |  Val. Acc: 83.48%\n",
            "\n",
            " 03/25/2021 03:50:24 Epoch: 3\n",
            "Completed 0/44\n",
            "\t Train Loss: 0.079 | Train Acc: 97.80%\n",
            "\t Val. Loss: 0.509 |  Val. Acc: 84.09%\n",
            "\n",
            " 03/25/2021 03:50:25 Epoch: 4\n",
            "Completed 0/44\n",
            "\t Train Loss: 0.080 | Train Acc: 97.44%\n",
            "\t Val. Loss: 0.517 |  Val. Acc: 83.13%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLsmS0s7kMVa"
      },
      "source": [
        "### Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kqt-juMJkMVa"
      },
      "source": [
        "#load weights\n",
        "#model.load_state_dict(torch.load(model_path));\n",
        "model.eval();\n",
        "\n",
        "def prepare_text(sentence):\n",
        "    text = text_pipeline(sentence)\n",
        "    text_length = len(text)\n",
        "    tensor = torch.tensor(text, dtype=torch.int64)\n",
        "    length = torch.tensor(text_length, dtype=torch.int64)\n",
        "    tensor = tensor.unsqueeze(0)\n",
        "    length = length.unsqueeze(0)\n",
        "    return tensor.to(device), length\n",
        "\n",
        "def predict(model, sentence):\n",
        "    tensor, length = prepare_text(sentence)\n",
        "    prediction = model(tensor, length)                  #prediction \n",
        "    return prediction.item()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-XtR-N7kMVa"
      },
      "source": [
        "def insincere_or_not(pred):\n",
        "    return 'Not Offensive' if pred > .5 else 'Hate Speech or Offensive'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOVIhvoxkMVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "524fa5b2-8d3a-49a6-eaaa-10d0c385413e"
      },
      "source": [
        "#sincere question\n",
        "pred = predict(model, \"What is your favorite person in history?\")\n",
        "print (insincere_or_not(pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not Offensive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haMG3d-CkMVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2337cbbb-da45-43c3-8d10-e461695a2979"
      },
      "source": [
        "#insincere question\n",
        "pred = predict(model, \"Ur a faggot and a bitch\")\n",
        "print (insincere_or_not(pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hate Speech or Offensive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS2aBpwBkMVa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIY4vg94kMVb"
      },
      "source": [
        "### Note\n",
        "\n",
        "This notebook used data and code from a blog in https://www.analyticsvidhya.com"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G0JqCU8kMVb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}